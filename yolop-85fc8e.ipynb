{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/hustvl/YOLOP.git","metadata":{"execution":{"iopub.status.busy":"2022-10-16T08:49:19.325761Z","iopub.execute_input":"2022-10-16T08:49:19.327037Z","iopub.status.idle":"2022-10-16T08:49:27.731925Z","shell.execute_reply.started":"2022-10-16T08:49:19.326981Z","shell.execute_reply":"2022-10-16T08:49:27.730527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!wget https://drive.google.com/file/d/1Ge-R8NTxG1eqd4zbryFo-1Uonuh0Nxyl/view?usp=sharing","metadata":{"execution":{"iopub.status.busy":"2022-10-13T18:00:10.46407Z","iopub.execute_input":"2022-10-13T18:00:10.464534Z","iopub.status.idle":"2022-10-13T18:00:12.231286Z","shell.execute_reply.started":"2022-10-13T18:00:10.464495Z","shell.execute_reply":"2022-10-13T18:00:12.229979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.remove(\"./da_seg_annotations.zip\")","metadata":{"execution":{"iopub.status.busy":"2022-10-16T18:25:33.2622Z","iopub.execute_input":"2022-10-16T18:25:33.262701Z","iopub.status.idle":"2022-10-16T18:25:33.328824Z","shell.execute_reply.started":"2022-10-16T18:25:33.262668Z","shell.execute_reply":"2022-10-16T18:25:33.327796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!wget https://drive.google.com/file/d/1lDNTPIQj_YLNZVkksKM25CvCHuquJ8AP/","metadata":{"execution":{"iopub.status.busy":"2022-10-13T18:15:34.488607Z","iopub.execute_input":"2022-10-13T18:15:34.489046Z","iopub.status.idle":"2022-10-13T18:15:36.567903Z","shell.execute_reply.started":"2022-10-13T18:15:34.48899Z","shell.execute_reply":"2022-10-13T18:15:36.566152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install gdown","metadata":{"execution":{"iopub.status.busy":"2022-10-17T21:23:25.482494Z","iopub.execute_input":"2022-10-17T21:23:25.482932Z","iopub.status.idle":"2022-10-17T21:23:49.092064Z","shell.execute_reply.started":"2022-10-17T21:23:25.482845Z","shell.execute_reply":"2022-10-17T21:23:49.090809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pwd","metadata":{"execution":{"iopub.status.busy":"2022-10-16T16:47:49.254976Z","iopub.execute_input":"2022-10-16T16:47:49.255441Z","iopub.status.idle":"2022-10-16T16:47:50.285418Z","shell.execute_reply.started":"2022-10-16T16:47:49.255405Z","shell.execute_reply":"2022-10-16T16:47:50.284135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gdown\n\nurl = 'https://drive.google.com/u/0/uc?id=1lDNTPIQj_YLNZVkksKM25CvCHuquJ8AP'\n\noutput = 'll_seg_annotations.zip'\n\ngdown.download(url, output, quiet=False)","metadata":{"execution":{"iopub.status.busy":"2022-10-17T21:23:59.450806Z","iopub.execute_input":"2022-10-17T21:23:59.451253Z","iopub.status.idle":"2022-10-17T21:24:03.56088Z","shell.execute_reply.started":"2022-10-17T21:23:59.451184Z","shell.execute_reply":"2022-10-17T21:24:03.55981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"url = 'https://drive.google.com/u/0/uc?id=1xy_DhUZRHR8yrZG3OwTQAHhYTnXn7URv'\n\noutput = 'da_seg_annotations.zip'\n\ngdown.download(url, output, quiet=False)","metadata":{"execution":{"iopub.status.busy":"2022-10-17T21:24:16.855828Z","iopub.execute_input":"2022-10-17T21:24:16.856191Z","iopub.status.idle":"2022-10-17T21:24:20.224101Z","shell.execute_reply.started":"2022-10-17T21:24:16.856157Z","shell.execute_reply":"2022-10-17T21:24:20.222802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"url = 'https://drive.google.com/u/0/uc?id=1Ge-R8NTxG1eqd4zbryFo-1Uonuh0Nxyl'\n\noutput = 'det_annotations.zip'\n\ngdown.download(url, output, quiet=False)","metadata":{"execution":{"iopub.status.busy":"2022-10-17T21:24:26.220815Z","iopub.execute_input":"2022-10-17T21:24:26.221178Z","iopub.status.idle":"2022-10-17T21:24:29.458552Z","shell.execute_reply.started":"2022-10-17T21:24:26.221146Z","shell.execute_reply":"2022-10-17T21:24:29.457484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pwd","metadata":{"execution":{"iopub.status.busy":"2022-10-15T09:45:32.213654Z","iopub.execute_input":"2022-10-15T09:45:32.214079Z","iopub.status.idle":"2022-10-15T09:45:33.26441Z","shell.execute_reply.started":"2022-10-15T09:45:32.214043Z","shell.execute_reply":"2022-10-15T09:45:33.263166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.makedirs('./dataset')","metadata":{"execution":{"iopub.status.busy":"2022-10-17T21:24:52.482179Z","iopub.execute_input":"2022-10-17T21:24:52.482575Z","iopub.status.idle":"2022-10-17T21:24:52.48748Z","shell.execute_reply.started":"2022-10-17T21:24:52.482542Z","shell.execute_reply":"2022-10-17T21:24:52.486453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.rmtree('./dataset')","metadata":{"execution":{"iopub.status.busy":"2022-10-16T18:26:00.581528Z","iopub.execute_input":"2022-10-16T18:26:00.581888Z","iopub.status.idle":"2022-10-16T18:26:10.976073Z","shell.execute_reply.started":"2022-10-16T18:26:00.58186Z","shell.execute_reply":"2022-10-16T18:26:10.974948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#! unzip ./det_annotations.zip -d ./'dataset root'","metadata":{"execution":{"iopub.status.busy":"2022-10-13T19:08:24.429034Z","iopub.execute_input":"2022-10-13T19:08:24.429646Z","iopub.status.idle":"2022-10-13T19:08:28.95847Z","shell.execute_reply.started":"2022-10-13T19:08:24.429574Z","shell.execute_reply":"2022-10-13T19:08:28.957188Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.chdir(\"./YOLOP/\")","metadata":{"execution":{"iopub.status.busy":"2022-10-17T21:28:14.671781Z","iopub.execute_input":"2022-10-17T21:28:14.672214Z","iopub.status.idle":"2022-10-17T21:28:14.678239Z","shell.execute_reply.started":"2022-10-17T21:28:14.672173Z","shell.execute_reply":"2022-10-17T21:28:14.676949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pwd","metadata":{"execution":{"iopub.status.busy":"2022-10-17T21:28:21.125884Z","iopub.execute_input":"2022-10-17T21:28:21.12625Z","iopub.status.idle":"2022-10-17T21:28:22.110285Z","shell.execute_reply.started":"2022-10-17T21:28:21.126219Z","shell.execute_reply":"2022-10-17T21:28:22.109139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -r requirements.txt","metadata":{"execution":{"iopub.status.busy":"2022-10-17T21:28:26.84467Z","iopub.execute_input":"2022-10-17T21:28:26.845678Z","iopub.status.idle":"2022-10-17T21:28:38.644774Z","shell.execute_reply.started":"2022-10-17T21:28:26.845634Z","shell.execute_reply":"2022-10-17T21:28:38.643493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import os\n#os.chdir(\"./YOLOP/\")\n!python tools/demo.py --source inference/images/0ace96c3-48481887.jpg --save-dir ../output/ --device 0","metadata":{"execution":{"iopub.status.busy":"2022-10-17T21:32:48.903166Z","iopub.execute_input":"2022-10-17T21:32:48.90361Z","iopub.status.idle":"2022-10-17T21:32:55.63294Z","shell.execute_reply.started":"2022-10-17T21:32:48.903566Z","shell.execute_reply":"2022-10-17T21:32:55.631662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir(\"./../output/\")","metadata":{"execution":{"iopub.status.busy":"2022-10-17T21:33:03.219308Z","iopub.execute_input":"2022-10-17T21:33:03.219696Z","iopub.status.idle":"2022-10-17T21:33:03.227801Z","shell.execute_reply.started":"2022-10-17T21:33:03.219657Z","shell.execute_reply":"2022-10-17T21:33:03.226755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Image\nfor i in os.listdir(\"./../output/\"):\n    print(\"../output/\"+str(i))\n    Image(\"../output/\"+str(i))\n    print(\"done\")\nImage(\"../output/0ace96c3-48481887.jpg\")","metadata":{"execution":{"iopub.status.busy":"2022-10-17T21:33:07.370019Z","iopub.execute_input":"2022-10-17T21:33:07.37042Z","iopub.status.idle":"2022-10-17T21:33:07.390321Z","shell.execute_reply.started":"2022-10-17T21:33:07.370388Z","shell.execute_reply":"2022-10-17T21:33:07.389444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pwd","metadata":{"execution":{"iopub.status.busy":"2022-10-15T11:16:15.246935Z","iopub.execute_input":"2022-10-15T11:16:15.247371Z","iopub.status.idle":"2022-10-15T11:16:16.339066Z","shell.execute_reply.started":"2022-10-15T11:16:15.247328Z","shell.execute_reply":"2022-10-15T11:16:16.33765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.rmtree('./dataset/')","metadata":{"execution":{"iopub.status.busy":"2022-10-15T11:18:03.388896Z","iopub.execute_input":"2022-10-15T11:18:03.389331Z","iopub.status.idle":"2022-10-15T11:18:03.395039Z","shell.execute_reply.started":"2022-10-15T11:18:03.389276Z","shell.execute_reply":"2022-10-15T11:18:03.393738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir(\"./dataset\")","metadata":{"execution":{"iopub.status.busy":"2022-10-16T18:21:03.890088Z","iopub.execute_input":"2022-10-16T18:21:03.89056Z","iopub.status.idle":"2022-10-16T18:21:03.898562Z","shell.execute_reply.started":"2022-10-16T18:21:03.890525Z","shell.execute_reply":"2022-10-16T18:21:03.897501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(os.listdir('./dataset/ll_seg_annotations/bdd_lane_gt/'))\nprint(len(os.listdir('./dataset/ll_seg_annotations/bdd_lane_gt/val/')))","metadata":{"execution":{"iopub.status.busy":"2022-10-17T21:25:50.316192Z","iopub.execute_input":"2022-10-17T21:25:50.316551Z","iopub.status.idle":"2022-10-17T21:25:50.329047Z","shell.execute_reply.started":"2022-10-17T21:25:50.31652Z","shell.execute_reply":"2022-10-17T21:25:50.3279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import zipfile\nwith zipfile.ZipFile(\"./ll_seg_annotations.zip\",\"r\") as z:\n    z.extractall(\"./dataset/ll_seg_annotations/\")","metadata":{"execution":{"iopub.status.busy":"2022-10-17T21:25:15.533696Z","iopub.execute_input":"2022-10-17T21:25:15.534395Z","iopub.status.idle":"2022-10-17T21:25:30.514805Z","shell.execute_reply.started":"2022-10-17T21:25:15.534358Z","shell.execute_reply":"2022-10-17T21:25:30.513791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir(\"./dataset/ll_seg_annotations/\")","metadata":{"execution":{"iopub.status.busy":"2022-10-16T18:16:43.70168Z","iopub.execute_input":"2022-10-16T18:16:43.702093Z","iopub.status.idle":"2022-10-16T18:16:43.711419Z","shell.execute_reply.started":"2022-10-16T18:16:43.702064Z","shell.execute_reply":"2022-10-16T18:16:43.71064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import os\n#os.makedirs(\"./dataset/da_seg_annotations/\")","metadata":{"execution":{"iopub.status.busy":"2022-10-15T11:38:12.834677Z","iopub.execute_input":"2022-10-15T11:38:12.835699Z","iopub.status.idle":"2022-10-15T11:38:12.841265Z","shell.execute_reply.started":"2022-10-15T11:38:12.835656Z","shell.execute_reply":"2022-10-15T11:38:12.839843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(os.listdir('./dataset/da_seg_annotations/bdd_seg_gt/'))\nprint(len(os.listdir('./dataset/da_seg_annotations/bdd_seg_gt/val/')))","metadata":{"execution":{"iopub.status.busy":"2022-10-17T21:26:25.606447Z","iopub.execute_input":"2022-10-17T21:26:25.606969Z","iopub.status.idle":"2022-10-17T21:26:25.62529Z","shell.execute_reply.started":"2022-10-17T21:26:25.606911Z","shell.execute_reply":"2022-10-17T21:26:25.624288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import zipfile\nwith zipfile.ZipFile(\"./da_seg_annotations.zip\",\"r\") as z:\n    z.extractall(\"./dataset/da_seg_annotations/\")","metadata":{"execution":{"iopub.status.busy":"2022-10-17T21:26:02.834844Z","iopub.execute_input":"2022-10-17T21:26:02.8352Z","iopub.status.idle":"2022-10-17T21:26:17.603663Z","shell.execute_reply.started":"2022-10-17T21:26:02.83517Z","shell.execute_reply":"2022-10-17T21:26:17.602618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.makedirs(\"./dataset/det_annotations/\")","metadata":{"execution":{"iopub.status.busy":"2022-10-15T11:42:05.379837Z","iopub.execute_input":"2022-10-15T11:42:05.380606Z","iopub.status.idle":"2022-10-15T11:42:05.385838Z","shell.execute_reply.started":"2022-10-15T11:42:05.380564Z","shell.execute_reply":"2022-10-15T11:42:05.384471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nprint(os.listdir('./dataset/det_annotations/data2/zwt/bdd/bdd100k/labels/100k/'))\nprint(len(os.listdir('./dataset/det_annotations/data2/zwt/bdd/bdd100k/labels/100k/val/')))","metadata":{"execution":{"iopub.status.busy":"2022-10-17T21:27:08.765218Z","iopub.execute_input":"2022-10-17T21:27:08.765584Z","iopub.status.idle":"2022-10-17T21:27:08.778949Z","shell.execute_reply.started":"2022-10-17T21:27:08.765551Z","shell.execute_reply":"2022-10-17T21:27:08.777801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import zipfile\nwith zipfile.ZipFile(\"./det_annotations.zip\",\"r\") as z:\n    z.extractall(\"./dataset/det_annotations/\")","metadata":{"execution":{"iopub.status.busy":"2022-10-17T21:26:42.058227Z","iopub.execute_input":"2022-10-17T21:26:42.058603Z","iopub.status.idle":"2022-10-17T21:26:59.842972Z","shell.execute_reply.started":"2022-10-17T21:26:42.05857Z","shell.execute_reply":"2022-10-17T21:26:59.841826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pwd","metadata":{"execution":{"iopub.status.busy":"2022-10-16T08:47:55.848376Z","iopub.execute_input":"2022-10-16T08:47:55.848824Z","iopub.status.idle":"2022-10-16T08:47:56.959066Z","shell.execute_reply.started":"2022-10-16T08:47:55.848789Z","shell.execute_reply":"2022-10-16T08:47:56.957641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cat YOLOP/lib/config/default.py","metadata":{"execution":{"iopub.status.busy":"2022-10-17T21:27:16.294431Z","iopub.execute_input":"2022-10-17T21:27:16.294807Z","iopub.status.idle":"2022-10-17T21:27:17.43385Z","shell.execute_reply.started":"2022-10-17T21:27:16.294772Z","shell.execute_reply":"2022-10-17T21:27:17.431289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pwd\n","metadata":{"execution":{"iopub.status.busy":"2022-10-16T18:05:03.644945Z","iopub.execute_input":"2022-10-16T18:05:03.645958Z","iopub.status.idle":"2022-10-16T18:05:04.693216Z","shell.execute_reply.started":"2022-10-16T18:05:03.645867Z","shell.execute_reply":"2022-10-16T18:05:04.692128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile /kaggle/working/YOLOP/lib/config/default.py \nimport os\nfrom yacs.config import CfgNode as CN\n\n\n_C = CN()\n\n_C.LOG_DIR = 'runs/'\n_C.GPUS = (0,1)     \n_C.WORKERS = 2 #8\n_C.PIN_MEMORY = False\n_C.PRINT_FREQ = 20\n_C.AUTO_RESUME = True       # Resume from the last training interrupt\n_C.NEED_AUTOANCHOR = False      # Re-select the prior anchor(k-means)    When training from scratch (epoch=0), set it to be ture!\n_C.DEBUG = False\n_C.num_seg_class = 2\n\n# Cudnn related params\n_C.CUDNN = CN()\n_C.CUDNN.BENCHMARK = True\n_C.CUDNN.DETERMINISTIC = False\n_C.CUDNN.ENABLED = True\n\n\n# common params for NETWORK\n_C.MODEL = CN(new_allowed=True)\n_C.MODEL.NAME = ''\n_C.MODEL.STRU_WITHSHARE = False     #add share_block to segbranch\n_C.MODEL.HEADS_NAME = ['']\n_C.MODEL.PRETRAINED = \"\"\n_C.MODEL.PRETRAINED_DET = \"\"\n_C.MODEL.IMAGE_SIZE = [640, 640]  # width * height, ex: 192 * 256\n_C.MODEL.EXTRA = CN(new_allowed=True)\n\n\n# loss params\n_C.LOSS = CN(new_allowed=True)\n_C.LOSS.LOSS_NAME = ''\n_C.LOSS.MULTI_HEAD_LAMBDA = None\n_C.LOSS.FL_GAMMA = 0.0  # focal loss gamma\n_C.LOSS.CLS_POS_WEIGHT = 1.0  # classification loss positive weights\n_C.LOSS.OBJ_POS_WEIGHT = 1.0  # object loss positive weights\n_C.LOSS.SEG_POS_WEIGHT = 1.0  # segmentation loss positive weights\n_C.LOSS.BOX_GAIN = 0.05  # box loss gain\n_C.LOSS.CLS_GAIN = 0.5  # classification loss gain\n_C.LOSS.OBJ_GAIN = 1.0  # object loss gain\n_C.LOSS.DA_SEG_GAIN = 0.2  # driving area segmentation loss gain\n_C.LOSS.LL_SEG_GAIN = 0.2  # lane line segmentation loss gain\n_C.LOSS.LL_IOU_GAIN = 0.2 # lane line iou loss gain\n\n\n# DATASET related params\n_C.DATASET = CN(new_allowed=True)\n_C.DATASET.DATAROOT = '/kaggle/input/bdd100k-dataset/bdd100k/bdd100k/images/100k'       # the path of images folder\n_C.DATASET.LABELROOT = '/kaggle/working/dataset/det_annotations/data2/zwt/bdd/bdd100k/labels/100k'      # the path of det_annotations folder\n_C.DATASET.MASKROOT = '/kaggle/working/dataset/da_seg_annotations/bdd_seg_gt'                # the path of da_seg_annotations folder\n_C.DATASET.LANEROOT = '/kaggle/working/dataset/ll_seg_annotations/bdd_lane_gt'               # the path of ll_seg_annotations folder\n_C.DATASET.DATASET = 'BddDataset'\n_C.DATASET.TRAIN_SET = 'train'\n_C.DATASET.TEST_SET = 'val'\n_C.DATASET.DATA_FORMAT = 'jpg'\n_C.DATASET.SELECT_DATA = False\n_C.DATASET.ORG_IMG_SIZE = [720, 1280]\n\n# training data augmentation\n_C.DATASET.FLIP = True\n_C.DATASET.SCALE_FACTOR = 0.25\n_C.DATASET.ROT_FACTOR = 10\n_C.DATASET.TRANSLATE = 0.1\n_C.DATASET.SHEAR = 0.0\n_C.DATASET.COLOR_RGB = False\n_C.DATASET.HSV_H = 0.015  # image HSV-Hue augmentation (fraction)\n_C.DATASET.HSV_S = 0.7  # image HSV-Saturation augmentation (fraction)\n_C.DATASET.HSV_V = 0.4  # image HSV-Value augmentation (fraction)\n# TODO: more augmet params to add\n\n\n# train\n_C.TRAIN = CN(new_allowed=True)\n_C.TRAIN.LR0 = 0.001  # initial learning rate (SGD=1E-2, Adam=1E-3)\n_C.TRAIN.LRF = 0.2  # final OneCycleLR learning rate (lr0 * lrf)\n_C.TRAIN.WARMUP_EPOCHS = 3.0\n_C.TRAIN.WARMUP_BIASE_LR = 0.1\n_C.TRAIN.WARMUP_MOMENTUM = 0.8\n\n_C.TRAIN.OPTIMIZER = 'adam'\n_C.TRAIN.MOMENTUM = 0.937\n_C.TRAIN.WD = 0.0005\n_C.TRAIN.NESTEROV = True\n_C.TRAIN.GAMMA1 = 0.99\n_C.TRAIN.GAMMA2 = 0.0\n\n_C.TRAIN.BEGIN_EPOCH = 0\n_C.TRAIN.END_EPOCH = 240\n\n_C.TRAIN.VAL_FREQ = 1\n_C.TRAIN.BATCH_SIZE_PER_GPU =16\n_C.TRAIN.SHUFFLE = True\n\n_C.TRAIN.IOU_THRESHOLD = 0.2\n_C.TRAIN.ANCHOR_THRESHOLD = 4.0\n\n# if training 3 tasks end-to-end, set all parameters as True\n# Alternating optimization\n_C.TRAIN.SEG_ONLY = False           # Only train two segmentation branchs\n_C.TRAIN.DET_ONLY = False           # Only train detection branch\n_C.TRAIN.ENC_SEG_ONLY = False       # Only train encoder and two segmentation branchs\n_C.TRAIN.ENC_DET_ONLY = False       # Only train encoder and detection branch\n\n# Single task \n_C.TRAIN.DRIVABLE_ONLY = False      # Only train da_segmentation task\n_C.TRAIN.LANE_ONLY = False          # Only train ll_segmentation task\n_C.TRAIN.DET_ONLY = False          # Only train detection task\n\n\n\n\n_C.TRAIN.PLOT = True                # \n\n# testing\n_C.TEST = CN(new_allowed=True)\n_C.TEST.BATCH_SIZE_PER_GPU = 16\n_C.TEST.MODEL_FILE = ''\n_C.TEST.SAVE_JSON = False\n_C.TEST.SAVE_TXT = False\n_C.TEST.PLOTS = True\n_C.TEST.NMS_CONF_THRESHOLD  = 0.001\n_C.TEST.NMS_IOU_THRESHOLD  = 0.6\n\n\ndef update_config(cfg, args):\n    cfg.defrost()\n    # cfg.merge_from_file(args.cfg)\n\n    if args.modelDir:\n        cfg.OUTPUT_DIR = args.modelDir\n\n    if args.logDir:\n        cfg.LOG_DIR = args.logDir\n    \n    # if args.conf_thres:\n    #     cfg.TEST.NMS_CONF_THRESHOLD = args.conf_thres\n\n    # if args.iou_thres:\n    #     cfg.TEST.NMS_IOU_THRESHOLD = args.iou_thres\n    \n\n\n    # cfg.MODEL.PRETRAINED = os.path.join(\n    #     cfg.DATA_DIR, cfg.MODEL.PRETRAINED\n    # )\n    #\n    # if cfg.TEST.MODEL_FILE:\n    #     cfg.TEST.MODEL_FILE = os.path.join(\n    #         cfg.DATA_DIR, cfg.TEST.MODEL_FILE\n    #     )\n\n    cfg.freeze()","metadata":{"execution":{"iopub.status.busy":"2022-10-18T13:28:21.398736Z","iopub.execute_input":"2022-10-18T13:28:21.399101Z","iopub.status.idle":"2022-10-18T13:28:21.407485Z","shell.execute_reply.started":"2022-10-18T13:28:21.39907Z","shell.execute_reply":"2022-10-18T13:28:21.40649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cat ./lib/config/default.py","metadata":{"execution":{"iopub.status.busy":"2022-10-17T22:38:01.453525Z","iopub.execute_input":"2022-10-17T22:38:01.454016Z","iopub.status.idle":"2022-10-17T22:38:02.515387Z","shell.execute_reply.started":"2022-10-17T22:38:01.453958Z","shell.execute_reply":"2022-10-17T22:38:02.513939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pwd","metadata":{"execution":{"iopub.status.busy":"2022-10-17T21:49:13.179213Z","iopub.execute_input":"2022-10-17T21:49:13.179652Z","iopub.status.idle":"2022-10-17T21:49:14.175951Z","shell.execute_reply.started":"2022-10-17T21:49:13.17961Z","shell.execute_reply":"2022-10-17T21:49:14.174688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile ./tools/test.py\nimport argparse\nimport os, sys\nBASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsys.path.append(BASE_DIR)\n\nimport pprint\nimport torch\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim\nimport torch.utils.data\nimport torch.utils.data.distributed\nimport torchvision.transforms as transforms\nimport numpy as np\nfrom lib.utils import DataLoaderX\nfrom tensorboardX import SummaryWriter\n\nimport lib.dataset as dataset\nfrom lib.config import cfg\nfrom lib.config import update_config\nfrom lib.core.loss import get_loss\nfrom lib.core.function import validate\nfrom lib.core.general import fitness\nfrom lib.models import get_net\nfrom lib.utils.utils import create_logger, select_device\n\ndef parse_args():\n    parser = argparse.ArgumentParser(description='Test Multitask network')\n\n    # philly\n    parser.add_argument('--modelDir',\n                        help='model directory',\n                        type=str,\n                        default='')\n    parser.add_argument('--logDir',\n                        help='log directory',\n                        type=str,\n                        default='runs/')\n    parser.add_argument('--weights', nargs='+', type=str, default='/data2/zwt/wd/YOLOP/runs/BddDataset/detect_and_segbranch_whole/epoch-169.pth', help='model.pth path(s)')\n    parser.add_argument('--conf_thres', type=float, default=0.001, help='object confidence threshold')\n    parser.add_argument('--iou_thres', type=float, default=0.6, help='IOU threshold for NMS')\n    args = parser.parse_args()\n\n    return args\n\ndef main():\n    # set all the configurations\n    args = parse_args()\n    update_config(cfg, args)\n\n    # TODO: handle distributed training logger\n    # set the logger, tb_log_dir means tensorboard logdir\n\n    logger, final_output_dir, tb_log_dir = create_logger(\n        cfg, cfg.LOG_DIR, 'test')\n\n    logger.info(pprint.pformat(args))\n    logger.info(cfg)\n\n    writer_dict = {\n        'writer': SummaryWriter(log_dir=tb_log_dir),\n        'train_global_steps': 0,\n        'valid_global_steps': 0,\n    }\n\n    # bulid up model\n    # start_time = time.time()\n    print(\"begin to bulid up model...\")\n    # DP mode\n    device = select_device(logger, batch_size=cfg.TEST.BATCH_SIZE_PER_GPU* len(cfg.GPUS)) if not cfg.DEBUG \\\n        else select_device(logger, 'cpu')\n    # device = select_device(logger, 'cpu')\n\n    model = get_net(cfg)\n    print(\"finish build model\")\n    \n    # define loss function (criterion) and optimizer\n    criterion = get_loss(cfg, device=device)\n\n    # load checkpoint model\n\n    # det_idx_range = [str(i) for i in range(0,25)]\n    model_dict = model.state_dict()\n    checkpoint_file = args.weights\n    #checkpoint_file = str(checkpoint_file)\n    logger.info(\"=> loading checkpoint '{}'\".format(checkpoint_file))\n    checkpoint = torch.load(checkpoint_file[0])\n    checkpoint_dict = checkpoint['state_dict']\n    # checkpoint_dict = {k: v for k, v in checkpoint['state_dict'].items() if k.split(\".\")[1] in det_idx_range}\n    model_dict.update(checkpoint_dict)\n    model.load_state_dict(model_dict)\n    logger.info(\"=> loaded checkpoint '{}' \".format(checkpoint_file))\n\n    model = model.to(device)\n    model.gr = 1.0\n    model.nc = 1\n    print('bulid model finished')\n\n    print(\"begin to load data\")\n    # Data loading\n    normalize = transforms.Normalize(\n        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n    )\n\n    valid_dataset = eval('dataset.' + cfg.DATASET.DATASET)(\n        cfg=cfg,\n        is_train=False,\n        inputsize=cfg.MODEL.IMAGE_SIZE,\n        transform=transforms.Compose([\n            transforms.ToTensor(),\n            normalize,\n        ])\n    )\n\n    # valid_loader = DataLoaderX(\n    #     valid_dataset,\n    #     batch_size=cfg.TEST.BATCH_SIZE_PER_GPU * len(cfg.GPUS),\n    #     shuffle=False,\n    #     num_workers=cfg.WORKERS,\n    #     pin_memory=cfg.PIN_MEMORY,\n    #     collate_fn=dataset.AutoDriveDataset.collate_fn\n    # )\n    valid_loader = DataLoaderX(\n        valid_dataset,\n        batch_size=cfg.TEST.BATCH_SIZE_PER_GPU * len(cfg.GPUS),\n        shuffle=False,\n        num_workers=cfg.WORKERS,\n        pin_memory=False,\n        collate_fn=dataset.AutoDriveDataset.collate_fn\n    )\n    print('load data finished')\n\n    epoch = 0 #special for test\n    da_segment_results,ll_segment_results,detect_results, total_loss,maps, times = validate(\n        epoch,cfg, valid_loader, valid_dataset, model, criterion,\n        final_output_dir, tb_log_dir, writer_dict,\n        logger, device\n    )\n    fi = fitness(np.array(detect_results).reshape(1, -1))\n    msg =   'Test:    Loss({loss:.3f})\\n' \\\n            'Driving area Segment: Acc({da_seg_acc:.3f})    IOU ({da_seg_iou:.3f})    mIOU({da_seg_miou:.3f})\\n' \\\n                      'Lane line Segment: Acc({ll_seg_acc:.3f})    IOU ({ll_seg_iou:.3f})  mIOU({ll_seg_miou:.3f})\\n' \\\n                      'Detect: P({p:.3f})  R({r:.3f})  mAP@0.5({map50:.3f})  mAP@0.5:0.95({map:.3f})\\n'\\\n                      'Time: inference({t_inf:.4f}s/frame)  nms({t_nms:.4f}s/frame)'.format(\n                          loss=total_loss, da_seg_acc=da_segment_results[0],da_seg_iou=da_segment_results[1],da_seg_miou=da_segment_results[2],\n                          ll_seg_acc=ll_segment_results[0],ll_seg_iou=ll_segment_results[1],ll_seg_miou=ll_segment_results[2],\n                          p=detect_results[0],r=detect_results[1],map50=detect_results[2],map=detect_results[3],\n                          t_inf=times[0], t_nms=times[1])\n    logger.info(msg)\n    print(\"test finish\")\n\n\nif __name__ == '__main__':\n    main()\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-10-17T21:56:45.411994Z","iopub.execute_input":"2022-10-17T21:56:45.412414Z","iopub.status.idle":"2022-10-17T21:56:45.423507Z","shell.execute_reply.started":"2022-10-17T21:56:45.412375Z","shell.execute_reply":"2022-10-17T21:56:45.422533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python tools/test.py --weights weights/End-to-end.pth\n\"\"\"\n=> creating runs/BddDataset/_2022-10-17-22-08\nNamespace(conf_thres=0.001, iou_thres=0.6, logDir='runs/', modelDir='', weights=['weights/End-to-end.pth'])\nAUTO_RESUME: False\nCUDNN:\n  BENCHMARK: True\n  DETERMINISTIC: False\n  ENABLED: True\nDATASET:\n  COLOR_RGB: False\n  DATAROOT: /kaggle/input/bdd100k-dataset/bdd100k/bdd100k/images/100k\n  DATASET: BddDataset\n  DATA_FORMAT: jpg\n  FLIP: True\n  HSV_H: 0.015\n  HSV_S: 0.7\n  HSV_V: 0.4\n  LABELROOT: /kaggle/working/dataset/det_annotations/data2/zwt/bdd/bdd100k/labels/100k\n  LANEROOT: /kaggle/working/dataset/ll_seg_annotations/bdd_lane_gt\n  MASKROOT: /kaggle/working/dataset/da_seg_annotations/bdd_seg_gt\n  ORG_IMG_SIZE: [720, 1280]\n  ROT_FACTOR: 10\n  SCALE_FACTOR: 0.25\n  SELECT_DATA: False\n  SHEAR: 0.0\n  TEST_SET: val\n  TRAIN_SET: train\n  TRANSLATE: 0.1\nDEBUG: False\nGPUS: (0, 1)\nLOG_DIR: runs/\nLOSS:\n  BOX_GAIN: 0.05\n  CLS_GAIN: 0.5\n  CLS_POS_WEIGHT: 1.0\n  DA_SEG_GAIN: 0.2\n  FL_GAMMA: 0.0\n  LL_IOU_GAIN: 0.2\n  LL_SEG_GAIN: 0.2\n  LOSS_NAME: \n  MULTI_HEAD_LAMBDA: None\n  OBJ_GAIN: 1.0\n  OBJ_POS_WEIGHT: 1.0\n  SEG_POS_WEIGHT: 1.0\nMODEL:\n  EXTRA:\n    \n  HEADS_NAME: ['']\n  IMAGE_SIZE: [640, 640]\n  NAME: \n  PRETRAINED: \n  PRETRAINED_DET: \n  STRU_WITHSHARE: False\nNEED_AUTOANCHOR: True\nPIN_MEMORY: False\nPRINT_FREQ: 20\nTEST:\n  BATCH_SIZE_PER_GPU: 24\n  MODEL_FILE: \n  NMS_CONF_THRESHOLD: 0.001\n  NMS_IOU_THRESHOLD: 0.6\n  PLOTS: True\n  SAVE_JSON: False\n  SAVE_TXT: False\nTRAIN:\n  ANCHOR_THRESHOLD: 4.0\n  BATCH_SIZE_PER_GPU: 24\n  BEGIN_EPOCH: 0\n  DET_ONLY: False\n  DRIVABLE_ONLY: False\n  ENC_DET_ONLY: False\n  ENC_SEG_ONLY: False\n  END_EPOCH: 240\n  GAMMA1: 0.99\n  GAMMA2: 0.0\n  IOU_THRESHOLD: 0.2\n  LANE_ONLY: False\n  LR0: 0.001\n  LRF: 0.2\n  MOMENTUM: 0.937\n  NESTEROV: True\n  OPTIMIZER: adam\n  PLOT: True\n  SEG_ONLY: False\n  SHUFFLE: True\n  VAL_FREQ: 1\n  WARMUP_BIASE_LR: 0.1\n  WARMUP_EPOCHS: 3.0\n  WARMUP_MOMENTUM: 0.8\n  WD: 0.0005\nWORKERS: 2\nnum_seg_class: 2\nbegin to bulid up model...\nUsing torch 1.11.0 CUDA:0 (Tesla P100-PCIE-16GB, 16280MB)\n\nfinish build model\n=> loading checkpoint '['weights/End-to-end.pth']'\n=> loaded checkpoint '['weights/End-to-end.pth']' \nbulid model finished\nbegin to load data\nbuilding database...\n100%|███████████████████████████████████| 10000/10000 [00:07<00:00, 1373.72it/s]\ndatabase build finish\nload data finished\n  0%|                                                   | 0/209 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:2227.)\n  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n100%|█████████████████████████████████████████| 209/209 [21:05<00:00,  6.06s/it]\n                 all       1e+04    1.08e+05      0.0855       0.892       0.765       0.439\nSpeed: 0.0/0.0/0.0 ms inference/NMS/total per 640x640 image at batch-size 48\nResults saved to runs/BddDataset/_2022-10-17-22-08/visualization\nTest:    Loss(0.504)\nDriving area Segment: Acc(0.974)    IOU (0.861)    mIOU(0.915)\nLane line Segment: Acc(0.705)    IOU (0.262)  mIOU(0.623)\nDetect: P(0.085)  R(0.892)  mAP@0.5(0.765)  mAP@0.5:0.95(0.439)\nTime: inference(0.0064s/frame)  nms(0.0008s/frame)\ntest finish\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-10-17T22:07:55.402683Z","iopub.execute_input":"2022-10-17T22:07:55.403139Z","iopub.status.idle":"2022-10-17T22:29:28.303537Z","shell.execute_reply.started":"2022-10-17T22:07:55.403106Z","shell.execute_reply":"2022-10-17T22:29:28.302353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Image\nprint(os.listdir('runs/BddDataset/_2022-10-17-22-08/visualization')[0])\nImage(os.listdir('runs/BddDataset/_2022-10-17-22-08/visualization')[0])","metadata":{"execution":{"iopub.status.busy":"2022-10-17T22:36:45.703028Z","iopub.execute_input":"2022-10-17T22:36:45.703487Z","iopub.status.idle":"2022-10-17T22:36:45.730846Z","shell.execute_reply.started":"2022-10-17T22:36:45.70345Z","shell.execute_reply":"2022-10-17T22:36:45.728816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python tools/train.py\n\n\"\"\"\n=> creating runs/BddDataset/_2022-10-17-22-40\nNamespace(conf_thres=0.001, dataDir='', iou_thres=0.6, local_rank=-1, logDir='runs/', modelDir='', prevModelDir='', sync_bn=False)\nAUTO_RESUME: False\nCUDNN:\n  BENCHMARK: True\n  DETERMINISTIC: False\n  ENABLED: True\nDATASET:\n  COLOR_RGB: False\n  DATAROOT: /kaggle/input/bdd100k-dataset/bdd100k/bdd100k/images/100k\n  DATASET: BddDataset\n  DATA_FORMAT: jpg\n  FLIP: True\n  HSV_H: 0.015\n  HSV_S: 0.7\n  HSV_V: 0.4\n  LABELROOT: /kaggle/working/dataset/det_annotations/data2/zwt/bdd/bdd100k/labels/100k\n  LANEROOT: /kaggle/working/dataset/ll_seg_annotations/bdd_lane_gt\n  MASKROOT: /kaggle/working/dataset/da_seg_annotations/bdd_seg_gt\n  ORG_IMG_SIZE: [720, 1280]\n  ROT_FACTOR: 10\n  SCALE_FACTOR: 0.25\n  SELECT_DATA: False\n  SHEAR: 0.0\n  TEST_SET: val\n  TRAIN_SET: train\n  TRANSLATE: 0.1\nDEBUG: False\nGPUS: (0, 1)\nLOG_DIR: runs/\nLOSS:\n  BOX_GAIN: 0.05\n  CLS_GAIN: 0.5\n  CLS_POS_WEIGHT: 1.0\n  DA_SEG_GAIN: 0.2\n  FL_GAMMA: 0.0\n  LL_IOU_GAIN: 0.2\n  LL_SEG_GAIN: 0.2\n  LOSS_NAME: \n  MULTI_HEAD_LAMBDA: None\n  OBJ_GAIN: 1.0\n  OBJ_POS_WEIGHT: 1.0\n  SEG_POS_WEIGHT: 1.0\nMODEL:\n  EXTRA:\n    \n  HEADS_NAME: ['']\n  IMAGE_SIZE: [640, 640]\n  NAME: \n  PRETRAINED: \n  PRETRAINED_DET: \n  STRU_WITHSHARE: False\nNEED_AUTOANCHOR: True\nPIN_MEMORY: False\nPRINT_FREQ: 20\nTEST:\n  BATCH_SIZE_PER_GPU: 24\n  MODEL_FILE: \n  NMS_CONF_THRESHOLD: 0.001\n  NMS_IOU_THRESHOLD: 0.6\n  PLOTS: True\n  SAVE_JSON: False\n  SAVE_TXT: False\nTRAIN:\n  ANCHOR_THRESHOLD: 4.0\n  BATCH_SIZE_PER_GPU: 24\n  BEGIN_EPOCH: 0\n  DET_ONLY: False\n  DRIVABLE_ONLY: False\n  ENC_DET_ONLY: False\n  ENC_SEG_ONLY: False\n  END_EPOCH: 240\n  GAMMA1: 0.99\n  GAMMA2: 0.0\n  IOU_THRESHOLD: 0.2\n  LANE_ONLY: False\n  LR0: 0.001\n  LRF: 0.2\n  MOMENTUM: 0.937\n  NESTEROV: True\n  OPTIMIZER: adam\n  PLOT: True\n  SEG_ONLY: False\n  SHUFFLE: True\n  VAL_FREQ: 1\n  WARMUP_BIASE_LR: 0.1\n  WARMUP_EPOCHS: 3.0\n  WARMUP_MOMENTUM: 0.8\n  WD: 0.0005\nWORKERS: 2\nnum_seg_class: 2\nbegin to bulid up model...\nUsing torch 1.11.0 CUDA:0 (Tesla P100-PCIE-16GB, 16280MB)\n\nload model to device\nbegin to load data\nbuilding database...\n100%|███████████████████████████████████| 70000/70000 [00:57<00:00, 1212.25it/s]\ndatabase build finish\nbuilding database...\n100%|███████████████████████████████████| 10000/10000 [00:03<00:00, 2871.33it/s]\ndatabase build finish\nload data finished\nbegin check anchors\nWARNING: Extremely small objects found. 16846 of 755957 labels are < 3 pixels in width or height.\nRunning kmeans for 9 anchors on 755927 points...\nthr=0.25: 0.9989 best possible recall, 4.41 anchors past thr\nn=9, img_size=640, metric_all=0.311/0.753-mean/best, past_thr=0.511-mean: 5,14,  10,27,  17,41,  26,63,  41,94,  62,142,  70,282,  102,204,  136,374\nEvolving anchors with Genetic Algorithm: fitness = 0.7777: 100%|█| 1000/1000 [06\nthr=0.25: 0.9992 best possible recall, 5.20 anchors past thr\nn=9, img_size=640, metric_all=0.355/0.778-mean/best, past_thr=0.518-mean: 4,11,  6,17,  9,25,  14,37,  21,51,  32,80,  50,101,  70,175,  103,276\ntensor([[[0.5127, 1.4133],\n         [0.7584, 2.1538],\n         [1.1498, 3.1530]],\n\n        [[0.8632, 2.2938],\n         [1.3254, 3.2077],\n         [2.0116, 4.9829]],\n\n        [[1.5652, 3.1451],\n         [2.1926, 5.4793],\n         [3.2136, 8.6193]]], device='cuda:0')\nNew anchors saved to model. Update model config to use these anchors in the future.\n=> start training...\nEpoch: [1][0/1459]\tTime 18.939s (18.939s)\tSpeed 2.5 samples/s\tData 7.163s (7.163s)\tLoss 0.67409 (0.67409)\nEpoch: [1][20/1459]\tTime 109.746s (65.080s)\tSpeed 0.4 samples/s\tData 105.650s (60.288s)\tLoss 0.66379 (0.66777)\nEpoch: [1][40/1459]\tTime 201.352s (110.422s)\tSpeed 0.2 samples/s\tData 197.292s (105.800s)\tLoss 0.66664 (0.66757)\nEpoch: [1][60/1459]\tTime 292.209s (155.650s)\tSpeed 0.2 samples/s\tData 287.487s (151.103s)\tLoss 0.66991 (0.66787)\nEpoch: [1][80/1459]\tTime 384.578s (201.248s)\tSpeed 0.1 samples/s\tData 380.154s (196.755s)\tLoss 0.66960 (0.66775)\nEpoch: [1][100/1459]\tTime 477.015s (247.059s)\tSpeed 0.1 samples/s\tData 471.812s (242.586s)\tLoss 0.66529 (0.66753)\nEpoch: [1][120/1459]\tTime 568.315s (292.925s)\tSpeed 0.1 samples/s\tData 563.900s (288.475s)\tLoss 0.66455 (0.66724)\nEpoch: [1][140/1459]\tTime 659.943s (338.858s)\tSpeed 0.1 samples/s\tData 656.055s (334.422s)\tLoss 0.65769 (0.66691)\nEpoch: [1][160/1459]\tTime 752.351s (384.800s)\tSpeed 0.1 samples/s\tData 747.782s (380.376s)\tLoss 0.66058 (0.66641)\nEpoch: [1][180/1459]\tTime 843.507s (430.679s)\tSpeed 0.1 samples/s\tData 839.375s (426.265s)\tLoss 0.65901 (0.66596)\nEpoch: [1][200/1459]\tTime 935.531s (476.564s)\tSpeed 0.1 samples/s\tData 931.340s (472.156s)\tLoss 0.65493 (0.66526)\nEpoch: [1][220/1459]\tTime 1028.489s (522.481s)\tSpeed 0.0 samples/s\tData 1023.460s (518.079s)\tLoss 0.66559 (0.66488)\nEpoch: [1][240/1459]\tTime 1120.506s (568.443s)\tSpeed 0.0 samples/s\tData 1116.357s (564.039s)\tLoss 0.66147 (0.66435)\nEpoch: [1][260/1459]\tTime 1211.881s (614.392s)\tSpeed 0.0 samples/s\tData 1206.745s (609.987s)\tLoss 0.65606 (0.66381)\nEpoch: [1][280/1459]\tTime 1303.442s (660.321s)\tSpeed 0.0 samples/s\tData 1298.941s (655.922s)\tLoss 0.65237 (0.66310)\nEpoch: [1][300/1459]\tTime 1395.020s (706.271s)\tSpeed 0.0 samples/s\tData 1390.946s (701.871s)\tLoss 0.64805 (0.66249)\nEpoch: [1][320/1459]\tTime 1486.221s (752.197s)\tSpeed 0.0 samples/s\tData 1482.244s (747.798s)\tLoss 0.65656 (0.66187)\nEpoch: [1][340/1459]\tTime 1578.854s (798.091s)\tSpeed 0.0 samples/s\tData 1574.037s (793.687s)\tLoss 0.65204 (0.66103)\nEpoch: [1][360/1459]\tTime 1670.619s (844.017s)\tSpeed 0.0 samples/s\tData 1666.185s (839.609s)\tLoss 0.64630 (0.66020)\nEpoch: [1][380/1459]\tTime 1764.141s (889.974s)\tSpeed 0.0 samples/s\tData 1759.439s (885.557s)\tLoss 0.64554 (0.65939)\nEpoch: [1][400/1459]\tTime 1855.425s (935.950s)\tSpeed 0.0 samples/s\tData 1851.084s (931.531s)\tLoss 0.63330 (0.65845)\nEpoch: [1][420/1459]\tTime 1946.158s (981.880s)\tSpeed 0.0 samples/s\tData 1940.958s (977.461s)\tLoss 0.62963 (0.65744)\nEpoch: [1][440/1459]\tTime 2036.114s (1027.766s)\tSpeed 0.0 samples/s\tData 2031.933s (1023.348s)\tLoss 0.64136 (0.65650)\nEpoch: [1][460/1459]\tTime 2128.551s (1073.631s)\tSpeed 0.0 samples/s\tData 2123.682s (1069.209s)\tLoss 0.63729 (0.65556)\nEpoch: [1][480/1459]\tTime 2219.066s (1119.463s)\tSpeed 0.0 samples/s\tData 2214.993s (1115.041s)\tLoss 0.63275 (0.65458)\nEpoch: [1][500/1459]\tTime 2310.638s (1165.292s)\tSpeed 0.0 samples/s\tData 2306.506s (1160.871s)\tLoss 0.63233 (0.65369)\nEpoch: [1][520/1459]\tTime 2402.636s (1211.099s)\tSpeed 0.0 samples/s\tData 2397.688s (1206.680s)\tLoss 0.63752 (0.65280)\nEpoch: [1][540/1459]\tTime 2496.183s (1256.948s)\tSpeed 0.0 samples/s\tData 2492.247s (1252.524s)\tLoss 0.62211 (0.65188)\nEpoch: [1][560/1459]\tTime 2588.909s (1302.859s)\tSpeed 0.0 samples/s\tData 2583.534s (1298.432s)\tLoss 0.62507 (0.65097)\nEpoch: [1][580/1459]\tTime 2680.524s (1348.784s)\tSpeed 0.0 samples/s\tData 2676.139s (1344.356s)\tLoss 0.62362 (0.65003)\nEpoch: [1][600/1459]\tTime 2774.342s (1394.750s)\tSpeed 0.0 samples/s\tData 2770.082s (1390.316s)\tLoss 0.61385 (0.64911)\nEpoch: [1][620/1459]\tTime 2867.495s (1440.762s)\tSpeed 0.0 samples/s\tData 2862.819s (1436.325s)\tLoss 0.62397 (0.64829)\nEpoch: [1][640/1459]\tTime 2959.526s (1486.800s)\tSpeed 0.0 samples/s\tData 2955.452s (1482.361s)\tLoss 0.61484 (0.64735)\nEpoch: [1][660/1459]\tTime 3052.003s (1532.834s)\tSpeed 0.0 samples/s\tData 3047.595s (1528.392s)\tLoss 0.61535 (0.64652)\nEpoch: [1][680/1459]\tTime 3144.498s (1578.874s)\tSpeed 0.0 samples/s\tData 3140.518s (1574.430s)\tLoss 0.61862 (0.64570)\nEpoch: [1][700/1459]\tTime 3236.669s (1624.918s)\tSpeed 0.0 samples/s\tData 3232.508s (1620.472s)\tLoss 0.61831 (0.64486)\nEpoch: [1][720/1459]\tTime 3328.310s (1670.961s)\tSpeed 0.0 samples/s\tData 3323.698s (1666.514s)\tLoss 0.61205 (0.64400)\nEpoch: [1][740/1459]\tTime 3420.475s (1716.997s)\tSpeed 0.0 samples/s\tData 3416.145s (1712.550s)\tLoss 0.61437 (0.64313)\nEpoch: [1][760/1459]\tTime 3510.611s (1763.011s)\tSpeed 0.0 samples/s\tData 3506.461s (1758.564s)\tLoss 0.61008 (0.64226)\nEpoch: [1][780/1459]\tTime 3600.715s (1808.984s)\tSpeed 0.0 samples/s\tData 3596.615s (1804.540s)\tLoss 0.60477 (0.64143)\nEpoch: [1][800/1459]\tTime 3691.814s (1854.909s)\tSpeed 0.0 samples/s\tData 3687.581s (1850.470s)\tLoss 0.61464 (0.64061)\nEpoch: [1][820/1459]\tTime 3784.735s (1900.829s)\tSpeed 0.0 samples/s\tData 3780.635s (1896.391s)\tLoss 0.60412 (0.63980)\nEpoch: [1][840/1459]\tTime 3879.417s (1946.811s)\tSpeed 0.0 samples/s\tData 3875.217s (1942.372s)\tLoss 0.60735 (0.63902)\nEpoch: [1][860/1459]\tTime 3974.868s (1992.873s)\tSpeed 0.0 samples/s\tData 3970.439s (1988.429s)\tLoss 0.60525 (0.63825)\nEpoch: [1][880/1459]\tTime 4069.531s (2038.988s)\tSpeed 0.0 samples/s\tData 4065.235s (2034.542s)\tLoss 0.60012 (0.63743)\nEpoch: [1][900/1459]\tTime 4164.369s (2085.161s)\tSpeed 0.0 samples/s\tData 4159.657s (2080.713s)\tLoss 0.59192 (0.63663)\nEpoch: [1][920/1459]\tTime 4258.828s (2131.386s)\tSpeed 0.0 samples/s\tData 4254.533s (2126.938s)\tLoss 0.60162 (0.63587)\nEpoch: [1][940/1459]\tTime 4352.943s (2177.661s)\tSpeed 0.0 samples/s\tData 4348.725s (2173.212s)\tLoss 0.59347 (0.63510)\nEpoch: [1][960/1459]\tTime 4443.499s (2223.913s)\tSpeed 0.0 samples/s\tData 4438.385s (2219.466s)\tLoss 0.60626 (0.63438)\nEpoch: [1][980/1459]\tTime 4534.322s (2270.136s)\tSpeed 0.0 samples/s\tData 4529.686s (2265.690s)\tLoss 0.59254 (0.63365)\nEpoch: [1][1000/1459]\tTime 4625.931s (2316.335s)\tSpeed 0.0 samples/s\tData 4620.911s (2311.887s)\tLoss 0.59282 (0.63288)\nEpoch: [1][1020/1459]\tTime 4715.401s (2362.504s)\tSpeed 0.0 samples/s\tData 4711.138s (2358.059s)\tLoss 0.59089 (0.63211)\nEpoch: [1][1040/1459]\tTime 4804.658s (2408.612s)\tSpeed 0.0 samples/s\tData 4800.497s (2404.169s)\tLoss 0.59081 (0.63137)\nEpoch: [1][1060/1459]\tTime 4894.688s (2454.660s)\tSpeed 0.0 samples/s\tData 4890.434s (2450.218s)\tLoss 0.58941 (0.63064)\nEpoch: [1][1080/1459]\tTime 4985.485s (2500.685s)\tSpeed 0.0 samples/s\tData 4980.813s (2496.244s)\tLoss 0.59143 (0.62993)\nEpoch: [1][1100/1459]\tTime 5076.337s (2546.690s)\tSpeed 0.0 samples/s\tData 5071.696s (2542.248s)\tLoss 0.58503 (0.62920)\nEpoch: [1][1120/1459]\tTime 5166.232s (2592.663s)\tSpeed 0.0 samples/s\tData 5161.755s (2588.223s)\tLoss 0.59281 (0.62852)\nEpoch: [1][1140/1459]\tTime 5257.940s (2638.621s)\tSpeed 0.0 samples/s\tData 5253.916s (2634.180s)\tLoss 0.58919 (0.62780)\nEpoch: [1][1160/1459]\tTime 5349.968s (2684.579s)\tSpeed 0.0 samples/s\tData 5345.533s (2680.137s)\tLoss 0.58707 (0.62713)\nEpoch: [1][1180/1459]\tTime 5440.737s (2730.525s)\tSpeed 0.0 samples/s\tData 5436.482s (2726.083s)\tLoss 0.58256 (0.62643)\nEpoch: [1][1200/1459]\tTime 5532.017s (2776.458s)\tSpeed 0.0 samples/s\tData 5527.967s (2772.016s)\tLoss 0.58504 (0.62575)\nEpoch: [1][1220/1459]\tTime 5623.685s (2822.375s)\tSpeed 0.0 samples/s\tData 5618.775s (2817.933s)\tLoss 0.57981 (0.62504)\nEpoch: [1][1240/1459]\tTime 5714.748s (2868.292s)\tSpeed 0.0 samples/s\tData 5710.232s (2863.850s)\tLoss 0.57940 (0.62435)\nEpoch: [1][1260/1459]\tTime 5805.120s (2914.196s)\tSpeed 0.0 samples/s\tData 5801.013s (2909.755s)\tLoss 0.57636 (0.62365)\nEpoch: [1][1280/1459]\tTime 5896.618s (2960.084s)\tSpeed 0.0 samples/s\tData 5892.505s (2955.642s)\tLoss 0.58540 (0.62295)\nEpoch: [1][1300/1459]\tTime 5987.520s (3005.967s)\tSpeed 0.0 samples/s\tData 5983.272s (3001.525s)\tLoss 0.58122 (0.62229)\nEpoch: [1][1320/1459]\tTime 6078.507s (3051.830s)\tSpeed 0.0 samples/s\tData 6073.981s (3047.389s)\tLoss 0.57932 (0.62164)\nEpoch: [1][1340/1459]\tTime 6171.195s (3097.688s)\tSpeed 0.0 samples/s\tData 6167.013s (3093.245s)\tLoss 0.58797 (0.62099)\nEpoch: [1][1360/1459]\tTime 6265.439s (3143.575s)\tSpeed 0.0 samples/s\tData 6260.154s (3139.130s)\tLoss 0.57349 (0.62035)\nEpoch: [1][1380/1459]\tTime 6360.303s (3189.506s)\tSpeed 0.0 samples/s\tData 6355.213s (3185.059s)\tLoss 0.57928 (0.61971)\nEpoch: [1][1400/1459]\tTime 6456.312s (3235.481s)\tSpeed 0.0 samples/s\tData 6450.883s (3231.031s)\tLoss 0.56639 (0.61908)\nEpoch: [1][1420/1459]\tTime 6551.661s (3281.512s)\tSpeed 0.0 samples/s\tData 6545.703s (3277.059s)\tLoss 0.56669 (0.61847)\nEpoch: [1][1440/1459]\tTime 6647.918s (3327.594s)\tSpeed 0.0 samples/s\tData 6642.232s (3323.137s)\tLoss 0.58653 (0.61785)\n  0%|                                                   | 0/209 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:2227.)\n  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n100%|█████████████████████████████████████████| 209/209 [22:32<00:00,  6.47s/it]\n                 all       1e+04    1.08e+05      0.0254       0.701       0.368       0.141\nSpeed: 0.1/0.0/0.1 ms inference/NMS/total per 640x640 image at batch-size 48\nResults saved to runs/BddDataset/_2022-10-17-22-40/visualization\nEpoch: [1]    Loss(0.600)\nDriving area Segment: Acc(0.881)    IOU (0.564)    mIOU(0.711)\nLane line Segment: Acc(0.813)    IOU (0.049)  mIOU(0.459)\nDetect: P(0.025)  R(0.701)  mAP@0.5(0.368)  mAP@0.5:0.95(0.141)\nTime: inference(0.0055s/frame)  nms(0.0012s/frame)\n=> saving checkpoint to runs/BddDataset/_2022-10-17-22-40/epoch-1.pth\nTraceback (most recent call last):\n  File \"tools/train.py\", line 395, in <module>\n    main()\n  File \"tools/train.py\", line 323, in main\n    epoch, num_batch, num_warmup, writer_dict, logger, device, rank)\n  File \"/kaggle/working/YOLOP/lib/core/function.py\", line 77, in train\n    total_loss, head_losses = criterion(outputs, target, shapes,model)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/kaggle/working/YOLOP/lib/core/loss.py\", line 50, in forward\n    total_loss, head_losses = self._forward_impl(head_fields, head_targets, shapes, model)\n  File \"/kaggle/working/YOLOP/lib/core/loss.py\", line 112, in _forward_impl\n    lseg_da = BCEseg(drive_area_seg_predicts, drive_area_seg_targets)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py\", line 716, in forward\n    reduction=self.reduction)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\", line 3132, in binary_cross_entropy_with_logits\n    return torch.binary_cross_entropy_with_logits(input, target, weight, pos_weight, reduction_enum)\nRuntimeError: CUDA out of memory. Tried to allocate 90.00 MiB (GPU 0; 15.90 GiB total capacity; 14.88 GiB already allocated; 23.75 MiB free; 15.11 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-10-17T22:40:07.53324Z","iopub.execute_input":"2022-10-17T22:40:07.533685Z","iopub.status.idle":"2022-10-18T01:03:09.201059Z","shell.execute_reply.started":"2022-10-17T22:40:07.533643Z","shell.execute_reply":"2022-10-18T01:03:09.199681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cat tools/demo.py","metadata":{"execution":{"iopub.status.busy":"2022-10-18T01:18:35.040946Z","iopub.execute_input":"2022-10-18T01:18:35.04147Z","iopub.status.idle":"2022-10-18T01:18:36.088144Z","shell.execute_reply.started":"2022-10-18T01:18:35.041422Z","shell.execute_reply":"2022-10-18T01:18:36.086826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile tools/demo.py\nimport argparse\nimport os, sys\nimport shutil\nimport time\nfrom pathlib import Path\nimport imageio\n\nBASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsys.path.append(BASE_DIR)\n\nprint(sys.path)\nimport cv2\nimport torch\nimport torch.backends.cudnn as cudnn\nfrom numpy import random\nimport scipy.special\nimport numpy as np\nimport torchvision.transforms as transforms\nimport PIL.Image as image\n\nfrom lib.config import cfg\nfrom lib.config import update_config\nfrom lib.utils.utils import create_logger, select_device, time_synchronized\nfrom lib.models import get_net\nfrom lib.dataset import LoadImages, LoadStreams\nfrom lib.core.general import non_max_suppression, scale_coords\nfrom lib.utils import plot_one_box,show_seg_result\nfrom lib.core.function import AverageMeter\nfrom lib.core.postprocess import morphological_process, connect_lane\nfrom tqdm import tqdm\nnormalize = transforms.Normalize(\n        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n    )\n\ntransform=transforms.Compose([\n            transforms.ToTensor(),\n            normalize,\n        ])\n\n\ndef detect(cfg,opt):\n\n    logger, _, _ = create_logger(\n        cfg, cfg.LOG_DIR, 'demo')\n\n    device = select_device(logger,opt.device)\n    if os.path.exists(opt.save_dir):  # output dir\n        shutil.rmtree(opt.save_dir)  # delete dir\n    os.makedirs(opt.save_dir)  # make new dir\n    half = device.type != 'cpu'  # half precision only supported on CUDA\n\n    # Load model\n    model = get_net(cfg)\n    #print(opt.weights)\n    checkpoint = torch.load(opt.weights[0], map_location= device)\n    model.load_state_dict(checkpoint['state_dict'])\n    model = model.to(device)\n    if half:\n        model.half()  # to FP16\n\n    # Set Dataloader\n    if opt.source.isnumeric():\n        cudnn.benchmark = True  # set True to speed up constant image size inference\n        dataset = LoadStreams(opt.source, img_size=opt.img_size)\n        bs = len(dataset)  # batch_size\n    else:\n        dataset = LoadImages(opt.source, img_size=opt.img_size)\n        bs = 1  # batch_size\n\n\n    # Get names and colors\n    names = model.module.names if hasattr(model, 'module') else model.names\n    colors = [[random.randint(0, 255) for _ in range(3)] for _ in range(len(names))]\n\n\n    # Run inference\n    t0 = time.time()\n\n    vid_path, vid_writer = None, None\n    img = torch.zeros((1, 3, opt.img_size, opt.img_size), device=device)  # init img\n    _ = model(img.half() if half else img) if device.type != 'cpu' else None  # run once\n    model.eval()\n\n    inf_time = AverageMeter()\n    nms_time = AverageMeter()\n    \n    for i, (path, img, img_det, vid_cap,shapes) in tqdm(enumerate(dataset),total = len(dataset)):\n        img = transform(img).to(device)\n        img = img.half() if half else img.float()  # uint8 to fp16/32\n        if img.ndimension() == 3:\n            img = img.unsqueeze(0)\n        # Inference\n        t1 = time_synchronized()\n        det_out, da_seg_out,ll_seg_out= model(img)\n        t2 = time_synchronized()\n        # if i == 0:\n        #     print(det_out)\n        inf_out, _ = det_out\n        inf_time.update(t2-t1,img.size(0))\n\n        # Apply NMS\n        t3 = time_synchronized()\n        det_pred = non_max_suppression(inf_out, conf_thres=opt.conf_thres, iou_thres=opt.iou_thres, classes=None, agnostic=False)\n        t4 = time_synchronized()\n\n        nms_time.update(t4-t3,img.size(0))\n        det=det_pred[0]\n\n        save_path = str(opt.save_dir +'/'+ Path(path).name) if dataset.mode != 'stream' else str(opt.save_dir + '/' + \"web.mp4\")\n\n        _, _, height, width = img.shape\n        h,w,_=img_det.shape\n        pad_w, pad_h = shapes[1][1]\n        pad_w = int(pad_w)\n        pad_h = int(pad_h)\n        ratio = shapes[1][0][1]\n\n        da_predict = da_seg_out[:, :, pad_h:(height-pad_h),pad_w:(width-pad_w)]\n        da_seg_mask = torch.nn.functional.interpolate(da_predict, scale_factor=int(1/ratio), mode='bilinear')\n        _, da_seg_mask = torch.max(da_seg_mask, 1)\n        da_seg_mask = da_seg_mask.int().squeeze().cpu().numpy()\n        # da_seg_mask = morphological_process(da_seg_mask, kernel_size=7)\n\n        \n        ll_predict = ll_seg_out[:, :,pad_h:(height-pad_h),pad_w:(width-pad_w)]\n        ll_seg_mask = torch.nn.functional.interpolate(ll_predict, scale_factor=int(1/ratio), mode='bilinear')\n        _, ll_seg_mask = torch.max(ll_seg_mask, 1)\n        ll_seg_mask = ll_seg_mask.int().squeeze().cpu().numpy()\n        # Lane line post-processing\n        #ll_seg_mask = morphological_process(ll_seg_mask, kernel_size=7, func_type=cv2.MORPH_OPEN)\n        #ll_seg_mask = connect_lane(ll_seg_mask)\n\n        img_det = show_seg_result(img_det, (da_seg_mask, ll_seg_mask), _, _, is_demo=True)\n\n        if len(det):\n            det[:,:4] = scale_coords(img.shape[2:],det[:,:4],img_det.shape).round()\n            for *xyxy,conf,cls in reversed(det):\n                label_det_pred = f'{names[int(cls)]} {conf:.2f}'\n                plot_one_box(xyxy, img_det , label=label_det_pred, color=colors[int(cls)], line_thickness=2)\n        \n        if dataset.mode == 'images':\n            cv2.imwrite(save_path,img_det)\n\n        elif dataset.mode == 'video':\n            if vid_path != save_path:  # new video\n                vid_path = save_path\n                if isinstance(vid_writer, cv2.VideoWriter):\n                    vid_writer.release()  # release previous video writer\n\n                fourcc = 'mp4v'  # output video codec\n                fps = vid_cap.get(cv2.CAP_PROP_FPS)\n                h,w,_=img_det.shape\n                vid_writer = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*fourcc), fps, (w, h))\n            vid_writer.write(img_det)\n        \n        else:\n            cv2.imshow('image', img_det)\n            cv2.waitKey(1)  # 1 millisecond\n\n    print('Results saved to %s' % Path(opt.save_dir))\n    print('Done. (%.3fs)' % (time.time() - t0))\n    print('inf : (%.4fs/frame)   nms : (%.4fs/frame)' % (inf_time.avg,nms_time.avg))\n\n\n\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--weights', nargs='+', type=str, default='weights/End-to-end.pth', help='model.pth path(s)')\n    parser.add_argument('--source', type=str, default='inference/videos', help='source')  # file/folder   ex:inference/images\n    parser.add_argument('--img-size', type=int, default=640, help='inference size (pixels)')\n    parser.add_argument('--conf-thres', type=float, default=0.25, help='object confidence threshold')\n    parser.add_argument('--iou-thres', type=float, default=0.45, help='IOU threshold for NMS')\n    parser.add_argument('--device', default='cpu', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')\n    parser.add_argument('--save-dir', type=str, default='inference/output', help='directory to save results')\n    parser.add_argument('--augment', action='store_true', help='augmented inference')\n    parser.add_argument('--update', action='store_true', help='update all models')\n    opt = parser.parse_args()\n    with torch.no_grad():\n        detect(cfg,opt)","metadata":{"execution":{"iopub.status.busy":"2022-10-18T01:21:22.48431Z","iopub.execute_input":"2022-10-18T01:21:22.48473Z","iopub.status.idle":"2022-10-18T01:21:22.498906Z","shell.execute_reply.started":"2022-10-18T01:21:22.484691Z","shell.execute_reply":"2022-10-18T01:21:22.497465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python tools/demo.py --weights 'weights/End-to-end.pth' --source inference/images/8e1c1ab0-a8b92173.jpg --save-dir ../output/ --device 0","metadata":{"execution":{"iopub.status.busy":"2022-10-18T01:50:04.881502Z","iopub.execute_input":"2022-10-18T01:50:04.881938Z","iopub.status.idle":"2022-10-18T01:50:12.957508Z","shell.execute_reply.started":"2022-10-18T01:50:04.881904Z","shell.execute_reply":"2022-10-18T01:50:12.956182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python tools/demo.py --weights 'runs/BddDataset/_2022-10-17-22-40/epoch-1.pth' --source inference/images/8e1c1ab0-a8b92173.jpg --save-dir ../output/ --device 0","metadata":{"execution":{"iopub.status.busy":"2022-10-18T01:24:06.506096Z","iopub.execute_input":"2022-10-18T01:24:06.506528Z","iopub.status.idle":"2022-10-18T01:24:14.360792Z","shell.execute_reply.started":"2022-10-18T01:24:06.506491Z","shell.execute_reply":"2022-10-18T01:24:14.35948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pwd","metadata":{"execution":{"iopub.status.busy":"2022-10-18T02:15:36.399381Z","iopub.execute_input":"2022-10-18T02:15:36.39976Z","iopub.status.idle":"2022-10-18T02:15:37.392598Z","shell.execute_reply.started":"2022-10-18T02:15:36.399728Z","shell.execute_reply":"2022-10-18T02:15:37.391434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.chdir('./YOLOP')","metadata":{"execution":{"iopub.status.busy":"2022-10-18T02:16:03.414089Z","iopub.execute_input":"2022-10-18T02:16:03.414469Z","iopub.status.idle":"2022-10-18T02:16:03.419652Z","shell.execute_reply.started":"2022-10-18T02:16:03.414431Z","shell.execute_reply":"2022-10-18T02:16:03.418345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.listdir('runs/BddDataset/_2022-10-17-22-40/')","metadata":{"execution":{"iopub.status.busy":"2022-10-18T02:23:13.758699Z","iopub.execute_input":"2022-10-18T02:23:13.759076Z","iopub.status.idle":"2022-10-18T02:23:13.76841Z","shell.execute_reply.started":"2022-10-18T02:23:13.759045Z","shell.execute_reply":"2022-10-18T02:23:13.765301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir('./weights/')","metadata":{"execution":{"iopub.status.busy":"2022-10-18T01:11:52.264369Z","iopub.execute_input":"2022-10-18T01:11:52.264906Z","iopub.status.idle":"2022-10-18T01:11:52.275219Z","shell.execute_reply.started":"2022-10-18T01:11:52.264856Z","shell.execute_reply":"2022-10-18T01:11:52.273833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir('../output/')","metadata":{"execution":{"iopub.status.busy":"2022-10-18T01:50:18.254999Z","iopub.execute_input":"2022-10-18T01:50:18.255451Z","iopub.status.idle":"2022-10-18T01:50:18.26545Z","shell.execute_reply.started":"2022-10-18T01:50:18.255405Z","shell.execute_reply":"2022-10-18T01:50:18.264075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Image\nImage(\"../output/8e1c1ab0-a8b92173.jpg\")","metadata":{"execution":{"iopub.status.busy":"2022-10-18T01:50:22.246001Z","iopub.execute_input":"2022-10-18T01:50:22.246421Z","iopub.status.idle":"2022-10-18T01:50:22.262031Z","shell.execute_reply.started":"2022-10-18T01:50:22.246374Z","shell.execute_reply":"2022-10-18T01:50:22.260833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.chdir('/kaggle/working/YOLOP/runs/BddDataset/_2022-10-17-22-40')\n!pwd","metadata":{"execution":{"iopub.status.busy":"2022-10-18T13:22:37.886481Z","iopub.execute_input":"2022-10-18T13:22:37.886857Z","iopub.status.idle":"2022-10-18T13:22:38.973203Z","shell.execute_reply.started":"2022-10-18T13:22:37.886828Z","shell.execute_reply":"2022-10-18T13:22:38.972113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir('./runs/BddDataset/')","metadata":{"execution":{"iopub.status.busy":"2022-10-18T19:50:00.396106Z","iopub.execute_input":"2022-10-18T19:50:00.396484Z","iopub.status.idle":"2022-10-18T19:50:00.404794Z","shell.execute_reply.started":"2022-10-18T19:50:00.396453Z","shell.execute_reply":"2022-10-18T19:50:00.403248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'epoch-1.pth')","metadata":{"execution":{"iopub.status.busy":"2022-10-18T13:22:41.990262Z","iopub.execute_input":"2022-10-18T13:22:41.991282Z","iopub.status.idle":"2022-10-18T13:22:41.997961Z","shell.execute_reply.started":"2022-10-18T13:22:41.99123Z","shell.execute_reply":"2022-10-18T13:22:41.997049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.chdir('/kaggle/working/YOLOP/')\n!pwd","metadata":{"execution":{"iopub.status.busy":"2022-10-18T13:29:49.031012Z","iopub.execute_input":"2022-10-18T13:29:49.031368Z","iopub.status.idle":"2022-10-18T13:29:49.969958Z","shell.execute_reply.started":"2022-10-18T13:29:49.03134Z","shell.execute_reply":"2022-10-18T13:29:49.968731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cat tools/train.py","metadata":{"execution":{"iopub.status.busy":"2022-10-18T13:29:52.656857Z","iopub.execute_input":"2022-10-18T13:29:52.657232Z","iopub.status.idle":"2022-10-18T13:29:53.594442Z","shell.execute_reply.started":"2022-10-18T13:29:52.657198Z","shell.execute_reply":"2022-10-18T13:29:53.593345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -r requirements.txt","metadata":{"execution":{"iopub.status.busy":"2022-10-18T13:31:02.306234Z","iopub.execute_input":"2022-10-18T13:31:02.306618Z","iopub.status.idle":"2022-10-18T13:31:16.41301Z","shell.execute_reply.started":"2022-10-18T13:31:02.306579Z","shell.execute_reply":"2022-10-18T13:31:16.411619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python tools/train.py","metadata":{"execution":{"iopub.status.busy":"2022-10-18T13:31:16.415992Z","iopub.execute_input":"2022-10-18T13:31:16.416486Z","iopub.status.idle":"2022-10-18T19:48:21.5682Z","shell.execute_reply.started":"2022-10-18T13:31:16.416381Z","shell.execute_reply":"2022-10-18T19:48:21.565558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python tools/demo.py --weights runs/BddDataset/checkpoint.pth --source inference/images/0ace96c3-48481887.jpg","metadata":{"execution":{"iopub.status.busy":"2022-10-18T19:53:02.811709Z","iopub.execute_input":"2022-10-18T19:53:02.812182Z","iopub.status.idle":"2022-10-18T19:53:12.520913Z","shell.execute_reply.started":"2022-10-18T19:53:02.812142Z","shell.execute_reply":"2022-10-18T19:53:12.519551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.listdir('inference/output')","metadata":{"execution":{"iopub.status.busy":"2022-10-18T19:53:47.23539Z","iopub.execute_input":"2022-10-18T19:53:47.236367Z","iopub.status.idle":"2022-10-18T19:53:47.243405Z","shell.execute_reply.started":"2022-10-18T19:53:47.236323Z","shell.execute_reply":"2022-10-18T19:53:47.242357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Image\nImage('inference/output/0ace96c3-48481887.jpg')","metadata":{"execution":{"iopub.status.busy":"2022-10-18T19:55:00.45333Z","iopub.execute_input":"2022-10-18T19:55:00.454116Z","iopub.status.idle":"2022-10-18T19:55:00.472252Z","shell.execute_reply.started":"2022-10-18T19:55:00.454081Z","shell.execute_reply":"2022-10-18T19:55:00.471286Z"},"trusted":true},"execution_count":null,"outputs":[]}]}